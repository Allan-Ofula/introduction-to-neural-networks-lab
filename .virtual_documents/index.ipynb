














from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import array_to_img, img_to_array, load_img
import numpy as np
import os





# Directory path
train_data_dir = 'data/train'
test_data_dir = 'data/validation'

# Get all the data in the directory data/validation (132 images), and reshape them
test_generator = ImageDataGenerator().flow_from_directory(
        test_data_dir, 
        target_size=(64, 64), batch_size=132)

# Get all the data in the directory data/train (790 images), and reshape them
train_generator = ImageDataGenerator().flow_from_directory(
        train_data_dir, 
        target_size=(64, 64), batch_size=790)

# Create the datasets
train_images, train_labels = next(train_generator)
test_images, test_labels = next(test_generator)











# Preview an image
array_to_img(train_images[0])


# Preview another image
array_to_img(train_images[100])








# Preview the shape of both the images and labels for both the train and test sets (4 objects total)
print("Train images shape:", np.shape(train_images))
print("Train labels shape:", np.shape(train_labels))

print("Test images shape:", np.shape(test_images))
print("Test labels shape:", np.shape(test_labels))








# Reshape the train images 
train_img_unrow = train_img_unrow = train_images.reshape(train_images.shape[0], -1).T





# Preview the shape of train_img_unrow
print("train_img_unrow shape:", train_img_unrow.shape)





# Define appropriate m 
m = test_images.shape[0] 
test_img_unrow = test_images.reshape(m, -1).T


# Preview the shape of test_img_unrow
print("test_img_unrow shape:", test_img_unrow.shape)








# Run this cell; no need to edit
train_labels 





# Run this cell; no need to edit
train_generator.class_indices





# Your code here
train_labels_final = train_labels[:, 1].reshape(1, -1)


# Run this cell; no need to edit
np.shape(train_labels_final) 


# Your code here
test_labels_final = test_labels[:, 1].reshape(1, -1)


# Run this cell; no need to edit
np.shape(test_labels_final) 





# Preview train image at index 240
array_to_img(train_images[240])


# Preview train label at index 240
train_labels_final[:, 240]











# Your code here 
train_img_final = train_img_unrow / 255.
test_img_final = test_img_unrow / 255.

type(test_img_unrow)


























# Your code here
b = 0








# Define your function
def init_w(n):
    return np.zeros((n, 1))


# Call your function using appropriate parameters
w = init_w(train_img_final.shape[0])








# Define the propagation function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def propagate(w, b, x, y):
    m = x.shape[1]
    z = np.dot(w.T, x) + b
    y_hat = sigmoid(z)
    cost = (-1 / m) * np.sum(y * np.log(y_hat + 1e-8) + (1 - y) * np.log(1 - y_hat + 1e-8))  # stability
    dw = (1 / m) * np.dot(x, (y_hat - y).T)
    db = (1 / m) * np.sum(y_hat - y)
    
    return dw, db, cost


# Use the propogation function
dw, db, cost = propagate(w, b, train_img_final, train_labels_final)


print(dw)

print(db)

print(cost)








# Complete the function below using your propagation function to define dw, db and cost 
# Then use the formula above to update w and b in the optimization function 
def optimization(w, b, x, y, num_iterations, learning_rate, print_cost = False):
    
    costs = []
    
    for i in range(num_iterations):
        dw, db, cost = propagate(w, b, x, y)
        w = w - learning_rate * dw
        b = b - learning_rate * db
        
        # Record the costs and print them every 50 iterations
        if i % 50 == 0:
            costs.append(cost)
        if print_cost and i % 50 == 0:
            print ("Cost after iteration %i: %f" %(i, cost))
    
    return w, b, costs


# Run this block of code as is
w, b, costs = optimization(w, b, train_img_final, train_labels_final, 
                           num_iterations= 151, learning_rate = 0.0001, print_cost = True)








def prediction(w, b, x):
    l = x.shape[1]
    y_prediction = np.zeros((1, l))
    w = w.reshape(x.shape[0], 1)
    y_hat = sigmoid(np.dot(w.T, x) + b)
    p = y_hat
    
    for i in range(y_hat.shape[1]):
        y_prediction[0, i] = 1 if y_hat[0, i] > 0.5 else 0
        # Transform the probability into a binary classification using 0.5 as the cutoff
    return y_prediction





# Run this block of code as is
w = np.array([[0.035], [0.123], [0.217]])
b = 0.2
x = np.array([[0.2, 0.4, -1.2, -2], 
              [1, -2., 0.1, -1], 
              [0.2, 0.4, -1.2, -2]])

prediction(w, b, x)








# Review this code carefully
def model(x_train, y_train, x_test, y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):

    b = 0
    w = init_w(np.shape(x_train)[0]) 

    # Gradient descent (≈ 1 line of code)
    w, b, costs = optimization(w, b, x_train, y_train, num_iterations, learning_rate, print_cost)
    
    y_pred_test = prediction(w, b, x_test)
    y_pred_train = prediction(w, b, x_train)

    # Print train/test errors
    print('train accuracy: {} %'.format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))
    print('test accuracy: {} %'.format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))

    output = {'costs': costs, 
              'y_pred_test': y_pred_test,  
              'y_pred_train' : y_pred_train,  
              'w' : w, 
              'b' : b, 
              'learning_rate' : learning_rate, 
              'num_iterations': num_iterations}
    
    return output


# Run the model!
# ⏰ Expect your code to take several minutes to run
output = model(train_img_final, train_labels_final, test_img_final, test_labels_final,
               num_iterations=2000, learning_rate=0.005, print_cost=True)



